{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pabv-Z6gQRv",
        "outputId": "33fe1243-8c7d-47dc-914a-6f04095b3342"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cx5foFZZgN1O"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "from PIL import Image, ImageEnhance\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Flatten, Dropout, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.models import load_model, Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "ZLTNocRBhhg2",
        "outputId": "8d4526f6-308e-450f-8346-df277d539c10"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/archive'\n",
        "train_dir = os.path.join(data_dir, \"Training\")\n",
        "test_dir = os.path.join(data_dir, \"Testing\")\n",
        "\n",
        "IMAGE_SIZE = 128\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# مرحله ۱: جمع‌آوری مسیر همه تصاویر و برچسب‌ها\n",
        "all_image_paths, all_labels = [], []\n",
        "for label in os.listdir(train_dir):\n",
        "    folder = os.path.join(train_dir, label)\n",
        "    if not os.path.isdir(folder):\n",
        "        continue\n",
        "    for image_name in os.listdir(folder):\n",
        "        if image_name.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
        "            all_image_paths.append(os.path.join(folder, image_name))\n",
        "            all_labels.append(label)\n",
        "\n",
        "df = pd.DataFrame({'path': all_image_paths, 'label': all_labels})\n",
        "print(f\" قبل از پاک‌سازی: {len(df)}\")\n",
        "\n",
        "# مرحله ۲: حذف داده‌های تکراری و گمشده\n",
        "df.drop_duplicates(subset='path', inplace=True)\n",
        "df.dropna(inplace=True)\n",
        "df = df[df['path'].apply(lambda x: os.path.exists(x))]\n",
        "print(f\" بعد از پاک‌سازی: {len(df)}\")\n",
        "\n",
        "#  مرحله ۳: Stratified train/test Split\n",
        "train_df, test_df = train_test_split(\n",
        "    df,\n",
        "    test_size=0.2,\n",
        "    stratify=df['label'],\n",
        "    random_state=42)\n",
        "\n",
        "print(f\" Train: {len(train_df)} | Test: {len(test_df)}\")\n",
        "\n",
        "# مرحله ۴: tf.data.Dataset\n",
        "def preprocess_image(path, label):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, [IMAGE_SIZE, IMAGE_SIZE])\n",
        "    img = img / 255.0\n",
        "    return img, label\n",
        "\n",
        "label_to_index = {label: idx for idx, label in enumerate(sorted(df['label'].unique()))}\n",
        "train_df['label_idx'] = train_df['label'].map(label_to_index)\n",
        "test_df['label_idx'] = test_df['label'].map(label_to_index)\n",
        "\n",
        "train_paths = train_df['path'].values\n",
        "train_labels = tf.keras.utils.to_categorical(train_df['label_idx'].values, num_classes=len(label_to_index))\n",
        "test_paths = test_df['path'].values\n",
        "test_labels = tf.keras.utils.to_categorical(test_df['label_idx'].values, num_classes=len(label_to_index))\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((train_paths, train_labels))\n",
        "train_ds = train_ds.map(lambda x, y: preprocess_image(x, y)).batch(BATCH_SIZE).shuffle(1000)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((test_paths, test_labels))\n",
        "test_ds = test_ds.map(lambda x, y: preprocess_image(x, y)).batch(BATCH_SIZE)\n",
        "\n",
        "print(\"دیتاست‌های نهایی\")\n",
        "\n",
        "# مرحله ۵: لود مدل 1 و استخراج ویژگی‌ها\n",
        "model_view = load_model(\"view_classifier(s2-model1).keras\")\n",
        "feature_extractor_view = Sequential(model_view.layers[:-1])\n",
        "\n",
        "def extract_features(dataset):\n",
        "    X_img, X_view, Y = [], [], []\n",
        "    for batch_imgs, batch_labels in dataset:\n",
        "        feats = feature_extractor_view(batch_imgs, training=False)\n",
        "        X_img.append(batch_imgs.numpy())\n",
        "        X_view.append(feats.numpy())\n",
        "        Y.append(batch_labels.numpy())\n",
        "    return (np.vstack(X_img), np.vstack(X_view), np.vstack(Y))\n",
        "\n",
        "X_train_img, X_train_view, y_train = extract_features(train_ds)\n",
        "X_test_img, X_test_view, y_test = extract_features(test_ds)\n",
        "\n",
        "print(\" Feature extraction کامل شد.\")\n",
        "print(\"Train:\", X_train_img.shape, X_train_view.shape, y_train.shape)\n",
        "print(\"Test:\", X_test_img.shape, X_test_view.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "id": "N2ez6wDkgrKJ",
        "outputId": "1a34d2df-feb3-42c2-cca9-87aca9e65dba"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "random_indices = random.sample(range(len(train_paths)), 10)\n",
        "\n",
        "fig, axes = plt.subplots(2, 5, figsize=(15, 8))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i, idx in enumerate(random_indices):\n",
        "    img_path = train_paths[idx]\n",
        "    img = Image.open(img_path)\n",
        "    img = img.resize((224, 224))\n",
        "    axes[i].imshow(img)\n",
        "    axes[i].axis('off')\n",
        "    axes[i].set_title(f\"Label: {train_labels[idx]}\", fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "8u7zX5oWnnvr",
        "outputId": "e4bdb7b0-b1d6-405a-af14-8a87eebb3eb7"
      },
      "outputs": [],
      "source": [
        "feature_extractor_view.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 569
        },
        "id": "UfEPM1q9hf_b",
        "outputId": "1f5a550e-a277-4851-b53d-f18e644910ac"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, Concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "IMAGE_SIZE = 128\n",
        "\n",
        "# Base model (VGG16)\n",
        "base_model = VGG16(\n",
        "    input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\"\n",
        ")\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "for layer in base_model.layers[-4:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# ساخت شاخه تصویر\n",
        "img_input = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3), name=\"image_input\")\n",
        "x = base_model(img_input, training=False)\n",
        "x = Flatten()(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "\n",
        "# ساخت شاخه ویژگی نما\n",
        "view_input = Input(shape=(128,), name=\"view_input\")\n",
        "y = Dense(64, activation='relu')(view_input)\n",
        "\n",
        "# ترکیب دو شاخه\n",
        "combined = Concatenate()([x, y])\n",
        "z = Dropout(0.3)(combined)\n",
        "z = Dense(128, activation='relu')(z)\n",
        "z = Dropout(0.2)(z)\n",
        "\n",
        "num_classes = y_train.shape[1]\n",
        "output = Dense(num_classes, activation=\"softmax\")(z)\n",
        "\n",
        "# مدل نهایی\n",
        "final_model = Model(inputs=[img_input, view_input], outputs=output)\n",
        "\n",
        "final_model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-4),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"])\n",
        "\n",
        "final_model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLZ-Js4IhjIS",
        "outputId": "c810b398-2065-4760-e5a2-0f67991c1981"
      },
      "outputs": [],
      "source": [
        "history = final_model.fit(\n",
        "    [X_train_img, X_train_view], y_train,\n",
        "    validation_data=([X_test_img, X_test_view], y_test),\n",
        "    epochs=5,\n",
        "    batch_size=32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAEQWice1RYI"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "final_model.save('final-model+pre-s2.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_z0lPaauo8w"
      },
      "source": [
        "#**Classification** **Report**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "id": "TjXvtcHfKNYq",
        "outputId": "4db84083-4adf-4f26-9ecd-190dc98cb48d"
      },
      "outputs": [],
      "source": [
        "test_predictions = final_model.predict([X_test_img, X_test_view])\n",
        "y_pred = np.argmax(test_predictions, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=[str(c) for c in range(y_test.shape[1])]))\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=[str(c) for c in range(y_test.shape[1])],\n",
        "            yticklabels=[str(c) for c in range(y_test.shape[1])])\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPQNxS1Su30S"
      },
      "source": [
        "#**محاسبه ROC و AU**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "uaGcuFDXMM_W",
        "outputId": "94176dbd-aaa4-4cb2-d0e9-ce230900b686"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "y_true_bin = label_binarize(y_true, classes=list(range(y_test.shape[1])))\n",
        "n_classes = y_test.shape[1]\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "for i in range(n_classes):\n",
        "    fpr, tpr, _ = roc_curve(y_true_bin[:, i], test_predictions[:, i])\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, label=f\"Class {i} (AUC = {roc_auc:.2f})\")\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curves (One-vs-Rest)\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSPOy2kOPPk0",
        "outputId": "8f08d2e5-0a7f-44db-bfc4-6d6a2608de7f"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "test_dir = \"/content/drive/MyDrive/archive/Testing\"\n",
        "IMAGE_SIZE = 128\n",
        "BATCH_SIZE = 32\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_gen = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jevB0FaqxNN",
        "outputId": "b121b012-abf4-471f-d2f6-539371fed3ad"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "tumor_classes = list(test_gen.class_indices.keys())\n",
        "view_classes = [\"axial\", \"coronal\", \"sagittal\"]\n",
        "IMAGE_SIZE = 128\n",
        "\n",
        "y_pred = np.argmax(final_model.predict([X_test_img, X_test_view]), axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "report = classification_report(y_true, y_pred, target_names=tumor_classes, output_dict=True)\n",
        "\n",
        "f1_dict = {cls: report[cls]['f1-score'] for cls in tumor_classes}\n",
        "precision_dict = {cls: report[cls]['precision'] for cls in tumor_classes}\n",
        "recall_dict = {cls: report[cls]['recall'] for cls in tumor_classes}\n",
        "\n",
        "print(\" Performance metrics calculated for each tumor class.\")\n",
        "\n",
        "def detect_tumor_and_view(img_path, final_model, feature_extractor_view, model_view, image_size=IMAGE_SIZE):\n",
        "\n",
        "    try:\n",
        "        img = load_img(img_path, target_size=(image_size, image_size))\n",
        "        img_array = img_to_array(img) / 255.0\n",
        "        img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "        view_pred = model_view.predict(img_array)\n",
        "        view_class_idx = np.argmax(view_pred, axis=1)[0]\n",
        "        view_label = view_classes[view_class_idx]\n",
        "        view_feature = feature_extractor_view(img_array, training=False).numpy()\n",
        "\n",
        "        tumor_pred = final_model.predict([img_array, view_feature])\n",
        "        tumor_class_idx = np.argmax(tumor_pred, axis=1)[0]\n",
        "        tumor_label = tumor_classes[tumor_class_idx]\n",
        "\n",
        "        f1 = f1_dict.get(tumor_label, 0)\n",
        "        prec = precision_dict.get(tumor_label, 0)\n",
        "        rec = recall_dict.get(tumor_label, 0)\n",
        "\n",
        "        if \"notumor\" in tumor_classes and tumor_label == \"notumor\":\n",
        "            result = f\"No Tumor detected (Precision: {prec*100:.1f}%, Recall: {rec*100:.1f}%, F1: {f1*100:.1f}%)\\nView: {view_label}\"\n",
        "        else:\n",
        "            result = f\"Tumor: {tumor_label}\\n(Precision: {prec*100:.1f}%, Recall: {rec*100:.1f}%, F1: {f1*100:.1f}%)\\nView: {view_label}\"\n",
        "\n",
        "        plt.imshow(load_img(img_path))\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(result)\n",
        "        plt.show()\n",
        "\n",
        "        return tumor_label, view_label, f1, prec, rec\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\" Error processing the image:\", str(e))\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "DRTckX2UP_x5",
        "outputId": "acca5c66-45c7-4370-c964-8b312ae28a08"
      },
      "outputs": [],
      "source": [
        "result = detect_tumor_and_view(\n",
        "    \"/content/drive/MyDrive/h-archive/Testing/glioma1-sagittal/Te-gl_0161.jpg\",\n",
        "    final_model, feature_extractor_view, model_view)\n",
        "print(\"Prediction Result:\", result)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
